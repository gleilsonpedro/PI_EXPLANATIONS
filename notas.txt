-gerar contagem de features relevantes, somente para a classe 0
-testar com outros datasets 
- validar as explicacões para todos os datasets
- inserir graficos - facilitar a interpretação da explicação

Acuracia= 
Verdadeiros Positivos (VP)+Verdadeiros Negativos (VN) / Falsos Positivos (FP)+Falsos Negativos (FN) Verdadeiros Positivos(VP)+Verdadeiros Negativos (VN)
​
A sensibilidade (também chamada de recall) mede a proporção de exemplos positivos que foram corretamente identificados pelo modelo. É calculada como:

Sensibilidade = Verdadeiros Positivos (VP) / Verdadeiros Positivos (VP) + Falsos Negativos (FN)

​A sensibilidade indica o quão bem o modelo identifica a classe positiva.

É especialmente importante em problemas onde os falsos negativos (casos positivos classificados erroneamente como negativos) são críticos. Por exemplo, em diagnósticos médicos, um falso negativo pode ser muito perigoso.

- reduzir dimensdionalidade dos datasets grandes
- criar código removendo as features desnecessárias segundo a pi-explicacões para teste.



## NO ARTIGO O CÁLCULO DOS DELTAS É
"δ_j = (valor_atual - valor_extremo) * w_j"


Classe	Peso (w)	Valor Típico	Fórmula Delta
0	w > 0	Alto	(valor - min) * w
0	w < 0	Baixo	(valor - max) * w
1	w > 0	Baixo	(max - valor) * w	← Invertido!
1	w < 0	Alto	(min - valor) * w	← Invertido!


O que a PI-explicação mostra:

Para instâncias da classe 0: mostra as features que garantem que é dessa classe específica

Para instâncias da classe 1: mostra as features que excluem a possibilidade de ser classe 0






########## IDEIAS TEMAS

Comparação da pi exp´licação com outras técnicas (SHAP e LIME)
    Mostrar as vantagens das explicações em comparação com as outras
    Comparar a complexidade das explicações
    




    ***** pegar média das explicações

    opção de rejeição - adaptando o algoritimo com a minima.
