{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets disponíveis:\n",
      "[0] iris\n",
      "[1] wine\n",
      "[2] breast_cancer\n",
      "[3] digits\n",
      "[4] banknote_authentication\n",
      "[5] wine_quality\n",
      "[6] heart_disease\n",
      "[7] parkinsons\n",
      "[8] car_evaluation\n",
      "[9] diabetes_binary\n",
      "Classes disponíveis:\n",
      "[0] setosa\n",
      "[1] versicolor\n",
      "[2] virginica\n",
      "Instância 28 - PI-Explicação: ['petal length (cm) - 1.4']\n",
      "Classe original: 1\n",
      "Classe após perturbação: 0\n",
      "✔️ A PI-explicação está coerente, pois a remoção das features alterou a predição.\n"
     ]
    }
   ],
   "source": [
    "#ADICIONAR PERTURBAÇÃO NAS FEATURES DA INSTANCIA ESCOLHIDA PARA VALIDAR A PI-EXPLICAÇÃO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.load_datasets import carregar_dataset\n",
    "from models.train_model import treinar_modelo\n",
    "from explanations.pi_explanation import analisar_instancias, one_explanation\n",
    "\n",
    "# Escolher dataset\n",
    "datasets_disponiveis = ['iris', 'wine', 'breast_cancer', 'digits', 'banknote_authentication',\n",
    "                        'wine_quality', 'heart_disease', 'parkinsons', 'car_evaluation', 'diabetes_binary']\n",
    "print(\"Datasets disponíveis:\")\n",
    "for i, nome in enumerate(datasets_disponiveis):\n",
    "    print(f\"[{i}] {nome}\")\n",
    "\n",
    "dataset_idx = int(input(\"Digite o número do dataset desejado: \"))\n",
    "nome_dataset = datasets_disponiveis[dataset_idx]\n",
    "\n",
    "# Carregaando dataset\n",
    "X, y, class_names = carregar_dataset(nome_dataset)\n",
    "print(\"Classes disponíveis:\")\n",
    "for i, nome_classe in enumerate(class_names):\n",
    "    print(f\"[{i}] {nome_classe}\")\n",
    "\n",
    "# Escolhendo classe 0\n",
    "classe_0_idx = int(input(\"Digite o número da classe que será 0: \"))\n",
    "y_binario = [0 if label == classe_0_idx else 1 for label in y]\n",
    "\n",
    "# Treinando modelo\n",
    "modelo, X_test, y_test = treinar_modelo(X, y_binario, classe_0=0)\n",
    "\n",
    "# Escolhendo instância para análise\n",
    "idx_teste = int(input(f\"Escolha um índice de 0 a {len(X_test)-1} para testar: \"))\n",
    "X_test_instancia = X_test.iloc[[idx_teste]].copy()\n",
    "\n",
    "# Calculando PI-explicação usando a mesma lógica do main.py\n",
    "Vs = X_test_instancia.iloc[0].to_dict()\n",
    "feature_names = X_test.columns.tolist()\n",
    "\n",
    "delta = []\n",
    "w = modelo.coef_[0]\n",
    "for i, feature in enumerate(feature_names):\n",
    "    if w[i] < 0:\n",
    "        delta.append((Vs[feature] - X[feature].max()) * w[i])\n",
    "    else:\n",
    "        delta.append((Vs[feature] - X[feature].min()) * w[i])\n",
    "\n",
    "R = sum(delta) - modelo.decision_function(X_test_instancia)[0]\n",
    "\n",
    "pi_explicacao = one_explanation(Vs, delta, R, feature_names, modelo, X_test_instancia, X)\n",
    "print(f\"Instância {idx_teste} - PI-Explicação: {pi_explicacao}\")\n",
    "\n",
    "# Criando uma cópia perturbada da instância removendo as features explicativas\n",
    "X_test_perturbada = X_test_instancia.copy()\n",
    "for feature_explicativa in pi_explicacao:\n",
    "    feature = feature_explicativa.split(\" - \")[0]  # Extraindo apenas o nome da feature\n",
    "    X_test_perturbada[feature] = X[feature].mean()  # Substitui pelo valor médio da feature\n",
    "    X_test_perturbada[feature] = X[feature].mean()  # Substitui pelo valor médio da feature\n",
    "\n",
    "# Predição do modelo antes e depois da perturbação\n",
    "classe_original = modelo.predict(X_test_instancia)[0]\n",
    "classe_perturbada = modelo.predict(X_test_perturbada)[0]\n",
    "\n",
    "print(f\"Classe original: {classe_original}\")\n",
    "print(f\"Classe após perturbação: {classe_perturbada}\")\n",
    "\n",
    "# Validação\n",
    "if classe_original != classe_perturbada:\n",
    "    print(\"A PI-explicação está coerente, pois a remoção das features alterou a predição.\")\n",
    "else:\n",
    "    print(\"A PI-explicação pode estar incompleta ou imprecisa, pois a predição não mudou.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets disponíveis:\n",
      "[0] iris\n",
      "[1] wine\n",
      "[2] breast_cancer\n",
      "[3] digits\n",
      "[4] banknote_authentication\n",
      "[5] wine_quality\n",
      "[6] heart_disease\n",
      "[7] parkinsons\n",
      "[8] car_evaluation\n",
      "[9] diabetes_binary\n",
      "Classes disponíveis:\n",
      "[0] setosa\n",
      "[1] versicolor\n",
      "[2] virginica\n",
      "Instância 28 - PI-Explicação: ['petal length (cm) - 1.4']\n",
      "Classe original: 1\n",
      "Classe após perturbação: 0\n",
      "A PI-explicação está coerente, pois a remoção das features alterou a predição.\n"
     ]
    }
   ],
   "source": [
    "#ADICIONAR PERTURBAÇÃO NAS FEATURES DA INSTANCIA ESCOLHIDA PARA VALIDAR A PI-EXPLICAÇÃO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.load_datasets import carregar_dataset\n",
    "from models.train_model import treinar_modelo\n",
    "from explanations.pi_explanation import analisar_instancias, one_explanation\n",
    "\n",
    "# Escolher dataset\n",
    "datasets_disponiveis = ['iris', 'wine', 'breast_cancer', 'digits', 'banknote_authentication',\n",
    "                        'wine_quality', 'heart_disease', 'parkinsons', 'car_evaluation', 'diabetes_binary']\n",
    "print(\"Datasets disponíveis:\")\n",
    "for i, nome in enumerate(datasets_disponiveis):\n",
    "    print(f\"[{i}] {nome}\")\n",
    "\n",
    "dataset_idx = int(input(\"Digite o número do dataset desejado: \"))\n",
    "nome_dataset = datasets_disponiveis[dataset_idx]\n",
    "\n",
    "# Carregaando dataset\n",
    "X, y, class_names = carregar_dataset(nome_dataset)\n",
    "print(\"Classes disponíveis:\")\n",
    "for i, nome_classe in enumerate(class_names):\n",
    "    print(f\"[{i}] {nome_classe}\")\n",
    "\n",
    "# Escolhendo classe 0\n",
    "classe_0_idx = int(input(\"Digite o número da classe que será 0: \"))\n",
    "y_binario = [0 if label == classe_0_idx else 1 for label in y]\n",
    "\n",
    "# Treinando modelo\n",
    "modelo, X_test, y_test = treinar_modelo(X, y_binario, classe_0=0)\n",
    "\n",
    "# Escolhendo instância para análise\n",
    "idx_teste = int(input(f\"Escolha um índice de 0 a {len(X_test)-1} para testar: \"))\n",
    "X_test_instancia = X_test.iloc[[idx_teste]].copy()\n",
    "\n",
    "# Calculando PI-explicação usando a mesma lógica do main.py\n",
    "Vs = X_test_instancia.iloc[0].to_dict()\n",
    "feature_names = X_test.columns.tolist()\n",
    "\n",
    "delta = []\n",
    "w = modelo.coef_[0]\n",
    "for i, feature in enumerate(feature_names):\n",
    "    if w[i] < 0:\n",
    "        delta.append((Vs[feature] - X[feature].max()) * w[i])\n",
    "    else:\n",
    "        delta.append((Vs[feature] - X[feature].min()) * w[i])\n",
    "\n",
    "R = sum(delta) - modelo.decision_function(X_test_instancia)[0]\n",
    "\n",
    "pi_explicacao = one_explanation(Vs, delta, R, feature_names, modelo, X_test_instancia, X)\n",
    "print(f\"Instância {idx_teste} - PI-Explicação: {pi_explicacao}\")\n",
    "\n",
    "percentile_min = 5\n",
    "percentile_max = 95\n",
    "random_state=None\n",
    "\n",
    "if random_state is not None:\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "# Criando uma cópia perturbada da instância removendo as features explicativas\n",
    "X_test_perturbada = X_test_instancia.copy()\n",
    "for feature_explicativa in pi_explicacao:\n",
    "    feature = feature_explicativa.split(\" - \")[0]  # Extraindo apenas o nome da feature\n",
    "    min_val = np.percentile(X[feature], percentile_min) # Calcula o percentil mínimo\n",
    "    max_val = np.percentile(X[feature], percentile_max) # Calcula o percentil máximo\n",
    "\n",
    "    # Gera um valor aleatório dentro do intervalo dos percentis\n",
    "    X_test_perturbada[feature] = np.random.uniform(min_val, max_val)\n",
    "\n",
    "# Predição do modelo antes e depois da perturbação\n",
    "classe_original = modelo.predict(X_test_instancia)[0]\n",
    "classe_perturbada = modelo.predict(X_test_perturbada)[0]\n",
    "\n",
    "print(f\"Classe original: {classe_original}\")\n",
    "print(f\"Classe após perturbação: {classe_perturbada}\")\n",
    "\n",
    "# Validação\n",
    "if classe_original != classe_perturbada:\n",
    "    print(\"A PI-explicação está coerente, pois a remoção das features alterou a predição.\")\n",
    "else:\n",
    "    print(\"A PI-explicação pode estar incompleta ou imprecisa, pois a predição não mudou.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
